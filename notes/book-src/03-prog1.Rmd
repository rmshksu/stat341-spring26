# Day 3

## Announcements

Journals

- Needing assistance with R programming/separate course
    
    - Intro to R (STAT 726) exists and I think it's a good course. If you're concerned about your ability to learn the language for your career then it's a great option. If you're only concerned about passing the course then I don't recommend it.
    
    - Today's lecture is R programing and a lab, we'll go over things in detail.
    
    - *Relax*. Learning is sometimes accompanied with pain and frustration. I remove grades to allow you to handle those things without stress. 
    
    - If you're failing it's because you're learning. 
    
<br>

- Scattered lectures (Very good feedback!)

    - It'll be "fast" a little longer. The sooner we get out of "fundamentals of R and math" the sooner we can slow down and focus.
    
    - Most of the math stuff is meant for you to worry about later. It exists, you've seen it, now when you hit a snag you can refer back to it.
    
    - This is also the first time *this* course version has been offered so I ask your patience while I figure out what 75 minute lectures should contain.
    
<br>

- Why is there calculus/concerns over math

    - This is best shown as an example
    
<br>

>Error catching/illegal algebra

```
A <- matrix(c(1, 2, 3, 4), 2, 2, TRUE)
B <- matrix(c(1, 2, 3, 4, 5, 6), 3, 2, TRUE)

Error in A %*% B  : 
  non-conformable arguments
```

- What happened here?

<br>

Maximum Likelihood Estimation

```
model <- lm(y ~ x)
```

- What is this code doing?

$$
y = \beta_0 + \beta_1x + \epsilon
$$

***That's not it***

$$
y \sim N(\beta_0 + \beta_1 x, \sigma^2 \boldsymbol{I})
$$

- If you know matrices and you know distributional assumptions

    - This makes sense
    
- If you know what a derivative is then optimization isn't a far stretch

    - Which means this will make more sense
    
$$
\hat{\beta} = \frac{\partial L}{\partial \beta} L(y|\beta,\sigma^2)
$$

    - *This doesn't mean you're expected to do this it just means you're expected to not be lost when I say Maximum Likelihood Estimation* (You should be lost right now though because we haven't actually discussed it)
    
<br>

- Integral calculus

    - For this class: If I say "area under the curve" your instinct should be "integration"
    
    - You don't need to do it. You shouldn't be head first in the sauce if I say that something requires integration though. 
    
    - For future stats classes/anything to do with bayesian: To get the expected value of a continuous random variable we have to integrate. Often times this is done numerically but if you don't know how to take a univariate integral of a tractable function you probably are SOL in a math stats/bayesian classroom.

<br>

- Course expectations

    - This is a hard one.

    - "Regression analysis and statistical modeling familiarity"

    - Reality is often simpler:

```{r}
url = "https://raw.githubusercontent.com/rmshksu/teaching-data/refs/heads/main/cruisedata.csv"
cruise = read.csv(url) 
x1 = cruise$start_month # predictor 1
x2 = cruise$voyage_duration # predictor 2
y = cruise$infected # response

# by the end of this class 
# everything that outputs from this should make sense
model = lm(y ~ x1 + x2)
summary(model)
```

- If you get more than that out of this class... bonus?

    - Kansas wants you to know this. You will know it by the end, *trust in that*.

<br>

- Final projects

    - Let's do a brief example!
    
<br>

## Final project

Water quality

- [Introduction to the problem](https://rmshksu.github.io/stat341-spring26/misce/st341_fp_context.html)

<br>

Steps to getting a decent project together

- Step 1: Have data

    - CSIMS and Ambient tracking

- Step 2: Have a problem you can solve with that data

    - What did these stations do differently that contributed to them reaching acceptable levels?
    
- Step 3: Come up with a statistical method that would resolve or make progress on the problem

    - I'm going to slowly work through more complex methods at observing the causal factors in the data related to these changes. I'll start with basic linear models and put a hard stop at Generalized Linear Mixed Models. Then I can assess whether something else is needed.
    
- Step 4: Check if someone's done the hard work for you

    - This is a really common problem in econometrics and wildlife biology. Most of the time they solve the "problem" with GLMMs, so I'm certain that's a good avenue to explore. 
    
- Step 5: Explore the data

    - Summary statistics, basic graphics, simple model outputs
    
- Step 6: Propose your model

    - I know what my data has, I know how other people have worked through my problem in the past, thus I can now consider some options for modeling the process. 
    
- Step 7: Get results

    - The model either worked or it didn't. Here's how I know which it is.
    
- Step 8: Write about it!!

    - Even if the results are "null" (your efforts weren't "rewarded") you should record what you did and put it out there. That way when someone else hits Step 4 they can stop before they spend more time on it (or try a different way).

<br>

- Undergraduate research

    - The hiring market seeks this out more and more
    
    - We're in a freeze nationwide. When it ends they'll be hiring on qualification since everyone with "experience" will be fully employed.
    
    - Two things prevent success in scientific publications: Writing and results.
    
    - This is an opportunity to manage one of those barriers with ease (Hello)
    
- After the class

    - Opportunity to continue onwards (p u b l i s h)
    
    - Portfolio for hiring
    
    - URA
    
<br>

**Any questions?**

<br>

## R Programming Lab

Partner up if you so choose. Complete the following with the seed "73":

1. Define 3 scalars

\[
a = 3
\qquad\qquad
b = 5
\qquad\qquad
c = 0.25
\]

2. Define 3 vectors

\[
\boldsymbol{x} = \begin{bmatrix} 5 \\ 3 \\ 6 \end{bmatrix}
\qquad\qquad
\boldsymbol{y} = \begin{bmatrix} 11.3 \\ 8.97 \\ 9.82 \end{bmatrix}
\qquad\qquad
\boldsymbol{z} = \begin{bmatrix} a \\ b \\ c \end{bmatrix}
\]

3. Generate 3 standard normal values and save them to a variable named w.

4. Multiply w by a random uniform value bound between 1 and 5, then save it as the new w.

5. Define the matrix:

\[
\textbf{A} = \begin{bmatrix} \boldsymbol{x} + w_1 \\ \boldsymbol{y} + w_2 \\ \boldsymbol{z} + w_3 \end{bmatrix}
\]

6. Confirm the following is true:

\[
\textbf{AA}^{-1} = \textbf{I}
\]

7. Add a row of 3 gamma distributed values with shape equal to 2 and rate equal to 1/5.

8. Simulate 4 normally distributed data points with a mean equal to the trace of A and standard deviation of 5. Save them as a variable named q.

9. Add a column of 1s to the matrix A and define:

\[
\hat{\boldsymbol{\theta}} = (\boldsymbol{A}^\prime \boldsymbol{A})^{-1} \boldsymbol{A}^\prime \boldsymbol{q}
\]

10. Calculate the predicted values of q:

\[
\hat{\boldsymbol{q}} = \boldsymbol{A} \boldsymbol{\hat{\theta}}
\]

<br>

## R Programming

- If you're using Python, be warned

  - Python use means you're too comfortable to switch
  
  - I expect clean, decently optimized code
  
  - Strong rationale for every library
  
- Excel

  - Possible, reasonable
  
  - Not recommended
  
- Program R

  - "Scripting" language
  
  - Open-source (a.k.a. Free)
  
  - Highly accessible
  
  - Like Python, but easier to learn + slightly more performant
  
<br>

- General structure

  - Not a programming class
  
  - Today: quick overview, basic principles
  
  - Tomorrow: R Markdown and simple LaTeX
  
  - That's it, the rest is on you
  
  - Follow along + start messing around on your own
  
<br>

### R Studio

- "Interactive Development Environment" or IDE for short

  - Makes using and learning R much easier
  
  - Hands down the best "R only" IDE
  
- Other IDEs

  - Virtual Studio
  
  - JetBrains
  
  - VIM
  
  - My take: don't obsess. RStudio for R, VSCode if you become a programmer.
  
    - VIM users are the coffee snobs of tech
    
- R Studio walk-through

<br>

### Basic principles

- Documentation/commenting code

  - Every non-redundant line
  
```{r}
# mtcars base R dataset
data = mtcars

y = data$mpg # mpg
x1 = data$hp # horsepower 
x2 = data$wt # weight

# linear model predicting mpg with horsepower
m1 = lm(y ~ x1)

# predict mpg with weight
m2 = lm(y ~ x2)

# predict mpg with both
m3 = lm(y ~ x1 + x2)

# coefficients for each model
coef(m1)
coef(m2)
coef(m3)
```

- Helper functions

  - Build early, build often

  - Separate files (obviously can't do here)
  
```{r}
library(dplyr) # tidyverse data wrangling

# function to calculate means for x based on strata
strata_means = function(data,strata,x){
  out = data %>% 
    # group by strata
    group_by(.data[[strata]]) %>%
    # calculate mean of x per strata
    summarise(xbar = mean(.data[[x]]))
  # rename columns
  colnames(out) = c(strata,x)
  return(out) # return dataframe of means
}

# run function
strata_means(data,"vs","mpg")
```

- You would save this as `strata_means.R` and call it with `source("strata_means.R")`

  - Then you could run the function
  
  - Prevents "How did I do that thing?"
  
  - Easier to troubleshoot errors
  
<br>

- Explanatory code

  - Objects/elements/function are named in ways that don't require comments

- Naming conventions
  
  - camelCase
  
  - snake_case
  
  - PascalCase
  
  - kebab-case
  
  - UPPER_CASE
  
  - S.case (common in R)
  
- Just be consistent

  - Switching constantly creates confusion
  
  - I use a bastardized version of snake_case
  
  - You probably shouldn't copy me 
  
  - But that's between you and your creator
  
```{r}
# the right way to do snake_case in R

# arrows to define objects
cars_data     <- mtcars 

# equals for inline definition + underscores on all separators
mpg_model_1   <- lm(mpg ~ hp, data = cars_data) 

# consistent spacing for code & comments
model_1_coefs <- coef(mpg_model_1) 

# clear and explanatory code
print(model_1_coefs)
```

```{r, eval=FALSE}
# my jacked up way

# uppercase when the vibe fits
DOC_address = "data/DOCYearEndReportAllData.xlsx" 
# equal sign instead of arrows always for max laziness
polys = st_read("data/WBDHU8/WBDHU8mod.shp")
# inconsistent spacing of functions
kansas_map = maps::map("state", "kansas", fill = TRUE, plot = FALSE)
kansas_sf = st_as_sf(kansas_map) |> st_set_crs(4326)
dat24 = daq[[4]] # numbers don't get underscore delims
# no comment spacing / change above vs. inline comment whenever
df_tkn = subset(dat24,dat24$Pollutant == "TKN") 
# reversing naming conventions when the spirit guides me
sf_df = st_as_sf(df_tkn, coords = c("Long","Lat"), crs = 4326)
```

- You don't read this mess without a function dictionary

  - Spoiler alert: I never make those
  
<br>
  
- Error catching

  - Rather advanced technique
  
  - Still probably good to learn (?) I'm bad about it
  
```{r}
# function to calculate means for x based on strata
strata_means = function(data,strata,x){
  
  # error catch for non-numeric inputs
  if(is.numeric(data[[x]]) == FALSE){
    cat("Error: Variable input to be averaged is non-numeric.", "\n",
        "Please check str(data[[x]]) and confirm.", "\n",
        "Change to as.numeric(data[[x]]) if this is intended.")
  }
  else{
    out = data %>% 
      # group by strata
      group_by(.data[[strata]]) %>%
      # calculate mean of x per strata
      summarise(xbar = mean(.data[[x]]))
    # rename columns
    colnames(out) = c(strata,x)
    return(out) # return dataframe of means
  }
}

# run function
data$mpg = as.character(data$mpg)
strata_means(data,"vs","mpg")
```

<br>

## Go away