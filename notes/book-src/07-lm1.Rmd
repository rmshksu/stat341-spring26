# Day 7

```{r , message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)

card_kable <- function(
  data,
  title    = NULL,
  subtitle = NULL,
  caption  = NULL,
  width    = "85%",
  header_color = "#51288590"
) {
  # Build the kable table (HTML)
  tbl <- knitr::kable(
    data,
    format = "html",
    escape = FALSE
  ) |>
    kableExtra::kable_styling(
      full_width = FALSE,
      bootstrap_options = c("condensed", "hover")
    )

  tbl_html <- as.character(tbl)

  # Title bar
  header_html <- if (!is.null(title)) {
    sprintf(
      '<div style="background:%s; color:white; padding:6px 10px; font-weight:600; 
                  border-radius:8px 8px 0 0;">%s</div>',
      header_color, title
    )
  } else {
    ""
  }

  # Subtitle text (optional)
  subtitle_html <- if (!is.null(subtitle)) {
    sprintf(
      '<div style="padding:6px 10px; font-size:0.9em; color:#555;">%s</div>',
      subtitle
    )
  } else {
    ""
  }

  # Caption text (optional)
  caption_html <- if (!is.null(caption)) {
    sprintf(
      '<div style="padding:6px 10px; font-size:0.8em; color:#777; border-top:1px solid #eee;">%s</div>',
      caption
    )
  } else {
    ""
  }

  card_html <- paste0(
    '<div style="border:1px solid #ddd; border-radius:8px; margin:1em auto; width:', width, 
    '; box-shadow:0 2px 5px rgba(0,0,0,0.06); background:white;">',
      header_html,
      subtitle_html,
      '<div style="padding:8px 10px;">',
        tbl_html,
      '</div>',
      caption_html,
    '</div>'
  )

  knitr::asis_output(card_html)
}
```


## Review

- Linear model

\[
\boldsymbol{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k + \boldsymbol{\epsilon}
\]

\[
\boldsymbol{y} = \textbf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon}
\]

<br>

- Estimating $\boldsymbol{\beta}$ 

\[
(\boldsymbol{X}^\prime \boldsymbol{X})^{-1} \boldsymbol{X}^\prime \boldsymbol{y}
\]

<br>

\[
\underset{i}{\arg\min} \sum_{i=1}^n (\boldsymbol{y}_i - \boldsymbol{x}_i^\prime \boldsymbol{\beta})^2
\]

<br>

\[
\underset{i}{\arg\max} \mathcal{L}(\boldsymbol{y}|\boldsymbol{\beta},\sigma^2)
\]

<br>

- Ordinary least squares

```{r}
url = "https://raw.githubusercontent.com/rmshksu/teaching-data/refs/heads/main/heart.csv"
heart = read.csv(url) # heart biometrics data
y = heart$chol # serum cholesterol
x1 = heart$age # subject age
X = cbind(1,x1) # design matrix
# matrix form of ordinary least squares
bhat = solve(t(X)%*%X)%*%t(X)%*%y
bhat
```

<br>

- Using R's `lm()` method

```{r}
# linear model in R
lm(y ~ x1)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
par(mar = c(4.5,4.5,1,1))
plot(x1,y, type = "n",
     xlab = "Age",
     ylab = "Serum Cholesteorol")
abline(v = seq(30,70,10), col = "#d1d1d190")
abline(h = seq(200,500,100), col = "#d1d1d190")
points(x1,y, pch = 20, cex = 1.2, col = "#00000080")
abline(a = bhat[1], b = bhat[2], col = "gold", lwd = 3)
```

<br>

- `summary(lm(y ~ x))`

```{r}
# all basic summaries of R linear model
summary(lm(y ~ x1))
```

<br>

**Any questions?**

<br>

## Multivariate Normal Distributions

- Your (brief) introduction to math stats

  - STAT 510/610/770 will do it better
  
  - No hate mail

\[
\boldsymbol{y} = \begin{bmatrix} y_1 \\ y_2 \\ y_3 \end{bmatrix} 
\sim N\left(\begin{bmatrix} \mu_1 \\ \mu_2 \\ \mu_3 \end{bmatrix}, 
\begin{bmatrix} \sigma^2 & 0 & 0 \\
0 & \sigma^2 & 0 \\
0 & 0 & \sigma^2 \\
\end{bmatrix}\right)
\]

<br>

\[
\begin{bmatrix} \mu_1 \\ \mu_2 \\ \mu_3 \end{bmatrix} = \boldsymbol{\mu}
\]

\[
\begin{bmatrix} \sigma^2 & 0 & 0 \\
0 & \sigma^2 & 0 \\
0 & 0 & \sigma^2 \\
\end{bmatrix} = 
\sigma^2 \begin{bmatrix} 1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
\end{bmatrix} = \sigma^2 \textbf{I}
\]

<br>

\[
\boldsymbol{y} \sim N(\boldsymbol{\mu},\sigma^2 \textbf{I})
\]

<br>

- "i.i.d.": independent and identically distributed

  - Sometimes referred to as a random sample
  
  - Assume that all observations of $y$ arise from the same mean and variance
  
<br>

- Covariance 

\[
\text{Cov}(X,Y) = \mathbb{E}\left[(X - \mathbb{E}X)(Y - \mathbb{E}Y) \right] = \mathbb{E}XY - \mathbb{E}X \mathbb{E}Y
\]

<br>

```{r}
# covariance between two vectors
x = runif(3)
y = rnorm(3)
cov(x,y)
```

<br>

\[
\boldsymbol{y} \sim N(\boldsymbol{\mu},\boldsymbol{\Sigma})
\]

\[
\boldsymbol{\Sigma} = \begin{bmatrix}
\sigma_{y_{11}} & \sigma_{y_{12}} & ... \sigma_{y_{1p}} \\
\sigma_{y_{21}} & \sigma_{y_{22}} & ... \sigma_{y_{2p}} \\
\vdots & \vdots & \vdots \\
\sigma_{y_{n1}} & \sigma_{y_{n2}} ... & \sigma_{y_{np}}
\end{bmatrix}
\]

\[
\sigma_{y_{11}} = \sigma^2_{y_1}
\]

<br>

```{r}
# covariance of a matrix
x = cbind(runif(3),runif(3),runif(3))
cov(x)
```

<br>

- Joint distributions

\[
y_1,y_2,...,y_n \overset{\text{iid}}{\sim} N(\mu,\sigma^2)
\]

- Think of the multiplication rule for independent events

<br>

\[
f_{X,Y}(x,y) = N(\mu_{x,y},\sigma^2_{x,y})
\]

<br>

- Conditional distributions

\[
f_{Y|X}(y|x) = \frac{f_{X,Y}(x,y)}{f_{Y}(y)}
\]

<br>

- "Gelman" notation

\[
\left[ y|x \right] = \frac{\left[ x,y \right]}{\left[ y \right]}
\]

<br>



## The simplest model

```{r, warning=FALSE, message=FALSE, fig.align='center'}
url = "https://www.ncei.noaa.gov/data/oceans/archive/arc0204/0254384/1.1/data/0-data/67350/Group_Sightings_2018.csv"
dolphins = read.csv(url) # noaa dolphin sightings
```

```{r, warning=FALSE, message=FALSE, fig.align='center'}
par(mfrow = c(2,2), mar = c(4.5,4.5,3,1))
hist(dolphins$Water.Depth..m.,
     xlab = "Meters",
     main = "Water depth", col = "cyan")
hist(dolphins$Sequential.Sighting.Number,
     xlab = "Count",
     main = "Sequential Sighting Number",
     col = "#51288590")
hist(dolphins$Best.Estimate.of.Group.Size,
     xlab = "Count",
     main = "Best Estimate of Group Size",
     col = "white")
hist(dolphins$Temp...C., xlab = "Celcius",
     main = "Temperature", col = "maroon")
```

- Propose a model

  - What does this mean? (Whiteboard)
  
<br>

<br>

- Intercept-only
  
\[
\boldsymbol{y} = \beta_0 + \boldsymbol{\epsilon}
\]

```{r}
# sequential sighting
x = dolphins$Sequential.Sighting.Number

# estimated group size
y = dolphins$Best.Estimate.of.Group.Size

# intercept only model
m1 = lm(y ~ 1)

coef(m1)
```

<br>

- A few fun ways to look at this:

\[
\hat{\beta_0} = \bar{y} - \hat{\beta_1} \bar{x}
\]

\[
\underset{i}{\arg\min} \sum_{i=1}^n (y_i - \beta x)^2
\]

\[
\underset{i}{\arg\max} \mathcal{L}(y|\beta_0,\sigma^2)
\]

- An even more amusing one; what is the structure of $\boldsymbol{X}$ here?

\[
\boldsymbol{y} = \boldsymbol{X \beta} + \boldsymbol{\epsilon}
\]

<br>

```{r}
n = length(y) # sample size of y
n

j = matrix(1,n,1,T) # j vector

# j'j = n
t(j)%*%j

# (j'j)^-1 = 1/n
solve(t(j)%*%j)

# j'y = sum(y)
t(j)%*%y

sum(y)

# all together
solve(t(j)%*%j)%*%t(j)%*%y

# in a simpler form
(y%*%j)/n

mean(y)
```

```{r}
par(mar = c(4.5,4.5,1,1))
plot(x, y,
     col = "#00000050",
     pch = 19, cex = 1.1,
     xlab = "Sequential Sighting Number",
     ylab = "Estiamted Group Size")
abline(h = mean(y),
       col = "gold",
       lwd = 3)
```

  
- Simple linear model
  
\[
\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x} + \boldsymbol{\epsilon}
\]

\[
\mathbb{E}(\boldsymbol{\epsilon}) = 0
\]

<br>

\[
\mathbb{E}(\boldsymbol{\epsilon}) = \boldsymbol{y} - \hat{\boldsymbol{y}} = \boldsymbol{y} - (\beta_0 + \beta_1 \boldsymbol{x}) = 0
\]

- What is $\hat{\boldsymbol{y}}$?

  - The prediction of $\mathbb{E}(\boldsymbol{y})$
  
\[
\boldsymbol{y} \sim N(\beta_0 + \beta_1 \boldsymbol{x}, \sigma^2 \textbf{I})
\]

- $\mathbb{E}(\boldsymbol{y}) = \boldsymbol{\mu}$

  - $\hat{\boldsymbol{y}} = \hat{\boldsymbol{\mu}} = \widehat{\mathbb{E}(\boldsymbol{y})}$
  
<br>

- When we estimate $\hat{\boldsymbol{\beta}}$

  - We're predicting an expected value of an unknown population parameter
  
  - Think about assignment 2 question 11
  
<br>

- Goal: propose a model that represents the data generating process of $\boldsymbol{y}$

  - Ideal: capture the entire process
  
  - Reality: $\approx 50\%$ most of the time
  
<br>

\[
\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x} + \boldsymbol{\epsilon}
\]

```{r}
# simple linear regression
m2 = lm(y ~ x) # seq sighting as sole predictor
summary(m2)
```

```{r}
par(mar = c(4.5,4.5,1,1))
plot(x, y,
     col = "#00000050",
     pch = 19, cex = 1.1,
     xlab = "Sequential Sighting Number",
     ylab = "Estiamted Group Size")
abline(h = mean(y),
       col = "gold",
       lwd = 3)
abline(a = coef(m2)[1], b = coef(m2)[2],
       col = "red",
       lwd = 3)
```

- Why do we use an intercept only model?

  - How much better is model 2 versus model 1?
  
  - Which are you choosing if you had to?
  
<br>

## Live example

- R code

<br>

## Go away