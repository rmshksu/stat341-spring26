# Day 4

## Review

- PSA: I'm teaching "bad programming"
  
  - Don't send me hate mail years later if you properly learn
  
  - I know I'm dis-servicing you all but we have limited time
  
  - For example: We won't discuss OOP, S3 vectors, vectorization
  
    - Leave it in the TEVAL if you think I should teach a course on it

### Basic principles

- Documentation/commenting code

  - Every non-redundant line
  
```{r}
# mtcars base R dataset
data = mtcars

y = data$mpg # mpg
x1 = data$hp # horsepower 
x2 = data$wt # weight

# linear model predicting mpg with horsepower
m1 = lm(y ~ x1)

# predict mpg with weight
m2 = lm(y ~ x2)

# predict mpg with both
m3 = lm(y ~ x1 + x2)

# coefficients for each model
coef(m1)
coef(m2)
coef(m3)
```

- Helper functions

  - Build early, build often
  
```{r}
library(dplyr) # tidyverse data wrangling

# function to calculate means for x based on strata
strata_means = function(data,strata,x){
  out = data %>% 
    # group by strata
    group_by(.data[[strata]]) %>%
    # calculate mean of x per strata
    summarise(xbar = mean(.data[[x]]))
  # rename columns
  colnames(out) = c(strata,x)
  return(out) # return dataframe of means
}

# run function
strata_means(data,"vs","mpg")
```

- You would save this as `strata_means.R` and call it with `source("strata_means.R")`

  - Then you could run the function
  
  - Prevents "How did I do that thing?"
  
  - Easier to troubleshoot errors
  
<br>

- Explanatory code

  - Objects/elements/function are named in ways that don't require comments

- Naming conventions
  
  - camelCase
  
  - snake_case
  
  - PascalCase
  
  - kebab-case
  
  - UPPER_CASE
  
  - S.case (common in R)
  
- Just be consistent
  
```{r}
# the right way to do snake_case in R

# arrows to define objects
cars_data     <- mtcars 

# equals for inline definition + underscores on all separators
mpg_model_1   <- lm(mpg ~ hp, data = cars_data) 

# consistent spacing for code & comments
model_1_coefs <- coef(mpg_model_1) 

# clear and explanatory code
print(model_1_coefs)
```
  
<br>
  
- Error catching
  
```{r}
# function to calculate means for x based on strata
strata_means = function(data,strata,x){
  
  # error catch for non-numeric inputs
  if(is.numeric(data[[x]]) == FALSE){
    cat("Error: Variable input to be averaged is non-numeric.", "\n",
        "Please check str(data[[x]]) and confirm.", "\n",
        "Change to as.numeric(data[[x]]) if this is intended.")
  }
  else{
    out = data %>% 
      # group by strata
      group_by(.data[[strata]]) %>%
      # calculate mean of x per strata
      summarise(xbar = mean(.data[[x]]))
    # rename columns
    colnames(out) = c(strata,x)
    return(out) # return dataframe of means
  }
}

# run function
data$mpg = as.character(data$mpg)
strata_means(data,"vs","mpg")
```

### R Basics

- Data types

```{r}
# scalars/variables
a = 5
a

# vectors
x = c(1,2,3)
x

# matrices
A = matrix(c(x,x-1,x+3),3,3,T)
A

# data frame
df = data.frame(fruit = c("Apple", "Banana", "Orange"),
                ID = c(111,112,113),
                Count = c(5,12,2))
df

# list
ls = list(x = x, A = A, df = df)
ls
```

- Data elements

```{r}
# access vector elements by position
x[1]
x[3]

# matrix elements: [row,column]
A
A[3,1]

# dataframe$column or dataframe[["column"]]
df$fruit
df[["fruit"]]

# list[[element]]
ls[[2]]
ls[[2]][3,1]
```

- Data actions

```{r}
# change the elements of a dataframe column
df$ID = c(1,2,3)
df$ID

rownames(df) = c("R1","R2","R3") # rename rows
colnames(df) = c("C1","C2","C3") # rename columns
df
```

- Booleans

```{r}
df$C1
df$C1 == "Apple" # print true where apple is present
df$C1 != "Apple" # print true when not apple
```

- Extended print statements

```{r}
# single line
cat("The mean of column 3 is:", mean(df$C3), "\n")

# multiple lines using "\n" for breaks
cat("The variance of column 3 is:", var(df$C3), "\n",
    "The standard deviation of column 3 is:", sd(df$C3))
```

- Removing NA values

```{r}
df[1,1] = NA
na.omit(df) # removes all rows with NAs
df[,colSums(is.na(df)) == 0] # remove all columns with NAs
```

- Replacing NA values

```{r}
df[is.na(df)] = 0
df
```

<br>

- Derivatives

\[
\frac{d}{dx} x^2 = 2x
\qquad\qquad 
\frac{d}{dx} 8x = 8
\qquad\qquad
\frac{d}{dx} 9 = 0
\]

\[
\frac{d}{dx} x^2 - 8x + 9 = 2x - 8
\]


```{r}
#limit definition of derivative
lim_diff = function(f, x, h = 1e-5) { 
  # h should always be a small step size
  ddx = (f(x + h) - f(x)) / h
  return(ddx)
}

fx = function(x){x^2 - 8*x + 9}
lim_diff(fx,2) # evaluate at x = 2
```

- Optimization

\[
\text{argmax}\{f(x)\} = \frac{d}{dx}f(x) \overset{set}{=} 0
\]

\[
f(x) = 2400x - 2x^2
\]

\[
\begin{aligned}
\text{argmax}\{f(x)\} = \frac{d}{dx} 2400x - 2x^2 = 2400 - 4x \overset{set}{=} 0 \\
\\
2400 = 4x \\
\\
600 = x
\end{aligned}
\]

- Check second derivative

\[
\frac{d}{d^2 x} 2400x - 2x^2 = \frac{d}{dx} 2400 - 4x = -4 < 0
\]

- $x = 600$ is the absolute maximum of $f(x)$ 

  - $f(x)$ is *concave down*
  
```{r message=FALSE, warning=FALSE, echo=FALSE}
fx = function(x){(2400*x) - 2*(x^2)}
x = seq(-1900,3100,100)

plot(x, fx(x),
     ylab = "f(x)",
     type="l",
     lwd = 2,
     ylim=c(fx(3000), 1500000))
abline(v = 600, col = "red3", lwd = 2)
abline(h = fx(600), col = "gold", lwd = 2)
points(600, fx(600), cex = 2, lwd = 2)
text(1000,-900000, "x = 600")
text(1200,-2100000, "f(x) = 720000")
```

- Integrals

\[
\frac{d}{dx}x^2 = 2x
\qquad\qquad
\int 2x \ dx = \frac{2x^2}{2} + C = x^2 + C
\]

\[
\int_{1}^2 \frac{1}{x} \ dx = \ln(|2|) - \ln(|1|) \approx 0.693
\]

```{r message=FALSE, warning=FALSE, echo=FALSE}
fx = function(x){1/x}
x = seq(0.1,3,0.01)

plot(x,fx(x),ylab = "f(x)",type="l")
segments(1,0,1,fx(1))
segments(2,0,2,fx(2))
x1_fill = seq(1, 2, length.out = 100)
y1_fill = fx(x1_fill)
polygon(c(1, x1_fill, 2), c(-0.1, y1_fill, -0.1), col = "#512885", border = NA)
arrows(2,4,1.5,1,0.1, col = "#512885", lwd = 1.5)
text(2.35,4.3,"Area = 0.693" ,col = "#512885", cex = 1.2)
```

<br>

\[
X \sim \text{Exp}(\theta)
\]

<br>

\[
f_x(x) = \theta e^{-\theta x}
\]

<br>

\[
\mathbb{E}X = \int_0^{\infty} x f_x(x) \ dx  = \int_0^{\infty} x\theta e^{-\theta x} \ dx  = \frac{1}{\theta}
\]

<br>

\[
\mathbb{E}X^2 = \int_0^{\infty} x^2 f_x(x) \ dx  = \int_0^{\infty} x^2 \theta e^{-\theta x} \ dx  = \frac{2}{\theta^2}
\]

<br>

\[
\mathbb{V}X = \mathbb{E}X^2 - [\mathbb{E}X]^2 = \frac{2}{\theta^2} - \left( \frac{1}{\theta} \right)^2 = \frac{1}{\theta^2}
\]

<br>

- Numerical integration

\[
f(x) = x^2 - 2x + 3
\]

\[
\begin{aligned}
\int_1^3 x^2 - 2x + 3 \ dx = \left. \frac{x^3}{3}- x^2 + 3x \ \right|_1^3 =\\
\\
\left(\frac{3^3}{3} - 3^2 + 3(3) \right) - \left(\frac{1^3}{3}- 1^2 + 3(1) \right) =\\
\\
(3 - 9 + 9) - \left(\frac{1}{3} - 4 \right) =\\
\\
6 \frac{2}{3} \approx 6.67 \\
\end{aligned}
\]
  
```{r message=FALSE, warning=FALSE, echo=FALSE}
fx = function(x) {
  return(x^2 - 2*x + 3)
}

a = 1
b = 3
n = 10 

delta_x = (b - a) / n

x_left = seq(a, b - delta_x, by = delta_x)

x_curve = seq(-2, 5, length.out = 1000)
y_curve = fx(x_curve)

plot(x_curve, y_curve, type = "l", col = "blue", lwd = 2,
     main = paste("Riemann Sum with n =", n),
     xlab = "x", ylab = "f(x)",
     xlim = c(-2,5),
     ylim = c(1, max(y_curve) * 1.1))

for (i in 1:n) {
  
  x_start = x_left[i]
  x_end = x_start + delta_x
  height = fx(x_start)
  
  rect(x_start, 0, x_end, height,
       col = "#51288595", border = "black", lwd = 1)
}

lines(x_curve, y_curve, col = "black", lwd = 2)


riemann_sum_val = sum(fx(x_left) * delta_x)
legend("center", legend = paste("Sum =", round(riemann_sum_val, 4)),
       bty = "n")
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
n = 100

delta_x = (b - a) / n

x_left = seq(a, b - delta_x, by = delta_x)

x_curve = seq(-2, 5, length.out = 1000)
y_curve = fx(x_curve)

plot(x_curve, y_curve, type = "l", col = "blue", lwd = 2,
     main = paste("Riemann Sum with n =", n),
     xlab = "x", ylab = "f(x)",
     xlim = c(-2,5),
     ylim = c(1, max(y_curve) * 1.1))

for (i in 1:n) {
  
  x_start = x_left[i]
  x_end = x_start + delta_x
  height = fx(x_start)
  
  rect(x_start, 0, x_end, height,
       col = "#51288595", border = NA, lwd = 1)
}

lines(x_curve, y_curve, col = "black", lwd = 2)


riemann_sum_val = sum(fx(x_left) * delta_x)
legend("center", legend = paste("Sum =", round(riemann_sum_val, 4)),
       bty = "n")
```

- Monte Carlo integration

```{r}
fx = function(x){x^2 - 2*x + 3}

a = 1 # lower bound
b = 3 # upper bound
n = 100000 # n samples

# random simulation between a and b
x = runif(n, min = a, max = b)

# evaluate f(x) at simulations
mc_sim = fx(x)

# mean weighted by difference
mc_int = (b - a)*mean(mc_sim)
mc_int
```

\[
X \sim \text{Beta}(4,10)
\]

\[
\mathbb{E}X = ?
\qquad\qquad
\mathbb{V}X = ?
\]

```{r}
# simulate 10000 beta(4,10) r.v. realizations
mc_sim = rbeta(10000,4,10)
mean(mc_sim) # empirical mean
var(mc_sim) # variance
```

\[
\mathbb{E}X = \frac{4}{4+10} = \frac{4}{14} \approx 0.285
\]

\[
\mathbb{V}X = \frac{4 \times 10}{(4 + 10)^2 (4 + 10 + 1)} = \frac{40}{196 \times 15} = \frac{40}{2940} \approx 0.0136
\]

**Any questions?**

<br>

## (More) Advanced stuff

- For loops

```{r}
# mtcars data
data = mtcars
# split by vs
splt = split(mtcars,mtcars$vs)
# empty vector
out = c()

# "for each element of the list"
for(i in 1:length(splt)){
  # fill the vector with the mean mpg
  # of each list element
  out[i] = mean(splt[[i]]$mpg)
}

out # matches the strata_means() output
```

<br>

- Concatenate

```{r}
# a way to push extended strings onto objects
names(out) = paste0("vs = ", names(splt), sep = " ")

out # labels better match strata_means()
```

<br>

- Libraries/packages

```{r message=FALSE, warning=FALSE}
# install.packages("dplyr")
library(dplyr) # we've seen this a lot

# install.packages("readxl")
library(readxl) # excel files can't be read by default in R

# install.packages("nlme")
library(nlme) # generalized least squares
              # important for next week
```

- WARNING: If you use a package I haven't shown you in class

  - Bad things occur
  
  - Exception: ggplot2 (don't use geom_smooth)
  
    - Queue soap box
  
<br>

- That's the majority of it

- We'll learn more over time

<br>

## Advanced Programming

- We don't *need* strong skills to succeed here

- AI/LLMs

  - Don't let them write your code entirely
  
  - "Packing a suit case"
  
  - Use them like search engines
  
  - Good for "canned" solutions
  
- I always know when you use AI

  - I rarely say anything unless its **bad**
  
  - Don't be bad if you decide to use them
  
  - Learning sometimes involves pain, programming requires it
  
  - The fastest way out is through

- If you like this stuff, feel free to dive deep

  - I'm happy to help
  
<br>
  
- Programming focused "class choice" topics

  - High dimensional data analysis (more parameters than samples)
  
    - Very important for genetics/animal science
    
    - Convex optimization problems, nasty stuff
    
    - Abuse packages to survive
  
  - Neural networks
  
    - Agronomy/animal science
    
    - Fusion between "mathy" and "programming-y"
    
    - We'll talk about machine learning anyway, this is "advanced" ML
    
  - Monte Carlo / Markov Chain Monte Carlo
  
    - The programming solution to Bayesian
    
    - Sampling algorithm
    
    - Useful for anyone considering computational biology/genetics
    
<br>

## In-class activity

- R Markdown

- Assignment 2

<br>

## Go away
